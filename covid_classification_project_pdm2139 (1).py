# -*- coding: utf-8 -*-
"""COVID Classification Project pdm2139.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UIFbtPBMAA7RXx6rzimIWbfhfNwR6YX9

References
1. https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html
2. 
https://github.com/submagr/blindness-detection (Referred some Pytorch functionality from github submission by sa3762 for a blindness detection problem)

Data Processing
"""

import numpy as np
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset
import pandas as pd
import time
import copy
import os
from sklearn.model_selection import train_test_split
from google.colab import drive
drive.mount('/content/drive')
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
from matplotlib import pyplot as plt



BASE_DIR = "/content/drive/My Drive/Colab Notebooks/Project/"
TRAIN_CSV_PATH = os.path.join(BASE_DIR, "train.csv")
TRAIN_DIR = os.path.join(BASE_DIR, "train")
TEST_DIR = os.path.join(BASE_DIR, "test")

#Train Data
train_full = pd.read_csv(TRAIN_CSV_PATH)

BATCH_SIZE = 35

#Get GPU if it's available
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

CAT_LABELS = {
    "normal": 0,
    "viral": 1,
    "bacterial": 2,
    "covid": 3,
}

LABELS_CAT = {
    0: "normal",
    1: "viral",
    2: "bacterial",
    3: "covid"
}

#Define cutom Dataset class
class Covid_data(Dataset):
    def __init__(self, df, objs_dir, transform=None, is_train_dataset=True):
        self.df = df
        self.transform = transform
        self.is_train_dataset = is_train_dataset
        self.objs_dir = objs_dir

    def __len__(self):
        return len(self.df)

    def __getitem__(self, index):
        img = Image.open(os.path.join(self.objs_dir, self.df.loc[index, "filename"]))
        if self.transform:
            img = self.transform(img)
        label = None
        img = torch.cat([img, img, img], dim=0)
        if self.is_train_dataset:
            label = CAT_LABELS[self.df.loc[index, "label"]]
        return (img, label)

#Define the transform to be applied to data: Makes the data into a tensor and Resizes
transform = transforms.Compose([
    transforms.Resize((256,256)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation((-30, 30)),
    transforms.ToTensor(),
])

df = pd.read_csv(os.path.join(BASE_DIR, "train.csv"))
df = df.sample(frac=1).reset_index(drop=True)
#Split Data into training data and validation data
train_df = df.loc[:int(len(df)*0.8)].reset_index(drop=True)
val_df = df.loc[int(len(df)*0.8):].reset_index(drop=True)

train_dataset = Covid_data(train_df, TRAIN_DIR, transform=transform)
val_dataset = Covid_data(val_df, TRAIN_DIR, transform=transform)
print(f"Train dataset: {len(train_dataset)}; Val dataset: {len(val_dataset)}")

dataloaders = {
    0: DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE),
    1: DataLoader(val_dataset, shuffle=True, batch_size=BATCH_SIZE)
}

"""**Distribution of Labels in Training and Validation Data**"""

# plt.hist(np.array([train_dataset.__getitem__(i)[1] for i in range(len(train_dataset))]))
plt.hist(train_df.label)
plt.title("Training Data")
plt.savefig('Training_Labels.png')

plt.hist(val_df.label)
plt.title("Validation Dataset")
plt.savefig('Validation_Labels.png')

dataset_sizes = {
    0: len(train_dataset),
    1: len(val_dataset),
}

# loading a pre trained model
model = models.resnet18(pretrained=True)

#Choosing a requires_grad as false for now.
for parameters in model.parameters():
    parameters.requires_grad = False

#slecting number of features
model_ftrs = model.fc.in_features
model.fc = torch.nn.Linear(model_ftrs, len(CAT_LABELS.keys()))

model = model.to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=True)

num_epochs = 50
#Run for these many number of epochs

for epoch in range(num_epochs):
    for i in range(1):
        if i == 0:
            model.train()
        else:
            model.eval()

        predictions_list = []
        labels_list = []
        running_loss = 0.
        running_corrects = 0.

      #Training the weights through the code:   
        for bn, (inputs, labels) in enumerate(dataloaders[phase]):
            inputs = inputs.to(device)
            labels = labels.to(device)
            optimizer.zero_grad()
            with torch.set_grad_enabled(phase == 0):
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)
                if phase == 0:
                    loss.backward()
                    optimizer.step()
                predictions_list += preds.tolist()
                labels_list += labels.tolist()

            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)
        epoch_loss = running_loss/dataset_sizes[phase]
        epoch_acc = running_corrects.double()*100 / dataset_sizes[phase]

torch.save(model, "Preprocessed.pt")

torch.save(model, "Preprocessed.pt")

#Prepare test Data from the test dataset
#with test dataset and dataloader classes
print("Degub Check 1")
test_df = pd.read_csv(os.path.join(BASE_DIR, "test.csv"))
test_dataset = Covid_data(test_df, TEST_DIR,transform, is_train_dataset=False)
print("Degub Check 2")
test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE)
prediction_df = pd.DataFrame(columns=["id", "label"], index=range(len(test_df)))


#Evaluate the model
model.eval()
for i in range(len(test_df)):
    #locating Image
    print("Degub Check - loop running")
    img_id = test_dataset.df.loc[i, "id"]
    pred = model(torch.tensor(test_dataset[i][0].unsqueeze(dim=0), dtype=torch.float, device=device))
    pred_label = LABELS_CAT[pred[0].argmax().item()]
    prediction_df.loc[i] = {"id": img_id, "label": pred_label}
prediction_df.to_csv("/content/drive/My Drive/Colab Notebooks/Project/pdm2139.csv", index=False)

